# Crime Rate Dataset

---
title: Crime Rate Dataset analysis
author: Patrick Cullinane
date: "05/16/2022"
output: html_document
---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```


```{r}
library(dplyr)
library(ggplot2)
library(car)
library(ggpubr)
library(tidyverse)
library(rstatix)
library(ggstatsplot)

setwd("C:/Users/Laura/Documents/code/MA-541")
df <- read.csv("Crime_R.csv")


#str(df)
```

## Introduction

The Crime Rate dataset is comprised of data crime rate and associated variables collected in the United States at two different periods of time. The dataset is broken down into 27 columns and 47 rows. The dataset was developed by the University of Sheffield 

```{r}
dim(df)

names(df)
```

The first 13 columns consist of crime rate data and other measurements taken at a point in time, and the next set consists of the same data taken a decade later. Additionally there is a column called Southern which consists of a binary variable, 1 if a Southern state 0 otherwise. The Southern column applys to both sets of columns within the dataset. We are not told the exact date at which the data has been collected. Overall the data is a mixture of discrete, binary, continuous variables. 

```{r}
# split data into year 0 and year + 10 

df0 <- df %>%
  select(-ends_with('10'))
df10 <- df %>%
  select(ends_with('10'))

head(df0,2)
tail(df0,2)
```

## Experiment 1

The first question we will examine will be whether there is a relationship between Males per 1000 females and states classified as Southern. To accomplish this we will use 3 columns; Southern, Males, and Males10. As mentioned previously Southern is a binary variable while Males and Males10 are discrete variables. Males and Males10 both refer to the number of males per 1000 females in counted in a US State. 

To get an idea of the make-up of the data we look at the summary statistics.

```{r}
str(df[,c("Southern","Males","Males10")])
summary(df[,c("Southern","Males","Males10")])
```

Next let's look at how the data's shape using some plots. 

```{r}
df1 <- df[,c("Southern","Males")]
df2 <- df[,c("Southern","Males10")]
stem(df$Southern)
stem(df$Males)
stem(df$Males10)
```

We can see from the stem plots that we have more Southern states. We should note that although it is not explicity stated in the data what constitutes a Southern state the data seems to align with the US census bureau's definition of a Southern state. The US census counts 16 states in total as Southern States, which appears to align with our data. Alternatively we can see there are 31 "0" states which in total make 47 states counted in this dataset. We are not told what comprise the 31 non-Southern states. 

```{r}
sum(df$Southern == 1)
sum(df$Southern == 0)

boxplot(df[,c("Males","Males10")])
```

From the stem plots we can see that Males and Males10 both appear to be rightly skewed. We can examaine this in more detail using a histogram. 

```{r}
ggplot(df, aes(x=Males)) + 
 geom_histogram(aes(y=..density..), colour="black", fill="white")+
 geom_density(alpha=.2, fill="#FF6666")

ggplot(df, aes(x=Males10)) + 
 geom_histogram(aes(y=..density..), colour="black", fill="white")+
 geom_density(alpha=.2, fill="#FF6666")
```

More detailed examination with our histograms and density plots again show us that data may be skewed to the right. This will be important to note as we further examine whether there is a difference in means between groups of data. 

With this intuition we will examine using anova whether there is a significant difference in group means. To accomplish this we must first encode our the Southern column to match Males and Males10, and then stack the data frames on top of eachother. Next we will run an anova test on the data. 

Next we formulate the following hypothesis:
$$ H_0: \alpha_1 = \alpha_2 = \alpha_3 = \alpha_4 $$
$$ H_1: \alpha_l \neq \alpha_k $$
The null hypothesis states that all groups measured will be the same while the alternative hypothesis states there is a difference in atleast two of the groups. 

To proceed further we need to make four groups of data to compare. To do this we will map a new variable from Southern to Males10. We will stick with the current mapping of the Males and Southern column which is "1" if Southern otherwise "0". 

In the second group we will use "3" to denote a Southern state and "2" otherwise. In this way we will have 4 groups of Males. At this point we will have four groups: 0:Non-Southern Males, 1:Southern Males, 2:Non-Southern Males10, 3:Southern Males. To run the test we then stack the data on top of eachother to create one long column of Males and Southern variables. Additionally we establish that we will reject the null hypothesis at an alpha of 0.05.  

```{r}

df2$Southern <- ifelse(df2$Southern == 0, 2,3)
names(df2)[2] <- "Males"

df_stack <- rbind(df1,df2)
df_stack$Southern <- as.factor(df_stack$Southern)

aov_test <- aov(Males ~ Southern, data=df_stack)
summary(aov_test)

glm_test <- glm(Males ~ Southern, data=df_stack, family=quasipoisson)

summary(glm_test)
```

As we can see from our test there appears to be a signficant difference between atleast two of the groups as the p-value is below our threshold of 0.05. Our test does not tell us which groups are different so we need to perform further tests to gain more insight. 
 
Although it appears that we can proceed with post-hoc testing to compare groups from our previous examination of the underlying data's distribution we still need to check that the underlying assumption of normality is met.

To do this we will use both graphical methods and formally with the Shapiro-Wilk test. We will use the residuals of the anova test to test this assumption.

```{r}
par(mfrow = c(1,2))
hist(aov_test$residuals)
qqPlot(aov_test$residuals)
```

Graphically it appears that the residuals are not nornally distributed but we need to examine this more formally with a kruskal test. 

We formulate the null hypothesis that the data comes from a normal distribution and the alternative hypothesis that the data does not come from a normal distribution and we establish an alpha of 0.05. 


```{r}
kruskal.test(Males ~ Southern, data = df_stack)
```

From our test we can see that our p-value is below our establish alpha level so we can reject the null hypothesis that the data comes from a normal distribution. With this bit of information we will proceed with a non-parametric test. In this case we will use the Dunn test and we formulate the same hypothesis we used for the anova test: The null hypothesis that the groups are equal and the 



```{r}
ggbetweenstats(
  data = df_stack,
  x = "Southern",
  y = "Males",
  type = "nonparametric", 
  plot.type = "box",
  pairwise.comparisons = TRUE,
  pairwise.display = "significant",
  centrality.plotting = FALSE,
  bf.message = FALSE
)

```





```{r}
lm.fit <- lm(CrimeRate ~ ExpenditureYear0, data=df0)
summary(lm.fit)

plot(df0$CrimeRate, df$ExpenditureYear0)
abline(lm.fit, lwd=3, col="red")

par(mfrow = c(2,2))
plot(lm.fit)

```

```{r}
model <- lm(CrimeRate~.,data=df0)
summary(model)

lm.fit <- lm(
  CrimeRate ~ 
    Education + Youth + Wage + BelowWage 
    + ExpenditureYear0, data=df0)

lm.fit2 <- lm(
  CrimeRate ~
    Youth + Wage + BelowWage
    + ExpenditureYear0, data=df0
)

summary(lm.fit)
summary(lm.fit2)

anova(lm.fit, lm.fit2)


```

```{r}
lm.fit3 <- lm(
  CrimeRate ~ 
    + log10(Youth)
    + log10(Wage)
    + log10(BelowWage) 
    + log10(ExpenditureYear0), data=df0
)

lm.fit4 <- lm(
  CrimeRate ~ 
  + log10(Youth)
  + log10(BelowWage) 
  + log10(ExpenditureYear0), data=df0
)

summary(lm.fit3)
summary(lm.fit4)

anova(lm.fit3, lm.fit4)


```

### References:

1. www.statstutor.ac.uk
2. US Census


